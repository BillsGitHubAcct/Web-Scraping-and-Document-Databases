{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News title --> NASA Engineers Dream Big with Small Spacecraft\n",
      "News paragraph --> \n",
      "The first CubeSat mission to deep space will launch in May.\n"
     ]
    }
   ],
   "source": [
    "# Usea splinter here since the web page has to be fully rendered (js executed) before we are able to get\n",
    "# the latest title and paragraph \n",
    "with  Browser('chrome', **executable_path, headless=True) as browser:\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    # open web page\n",
    "    browser.visit(url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # find latest title and paragraph\n",
    "    news_title = soup.find('div', class_='content_title').a.text\n",
    "    news_p = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print('News title --> ' + news_title)\n",
    "print('News paragraph --> \\n' + news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL's Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image url --> //www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14884_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "with  Browser('chrome', **executable_path, headless=True) as browser:\n",
    "    jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    # open web page\n",
    "    browser.visit(jpl_url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Get url for image jpg\n",
    "    jpl_url = soup.find('div', class_= 'jpl_logo').a['href']\n",
    "    url_last = soup.find('div', class_='default floating_text_area ms-layer').footer.a['data-fancybox-href']\n",
    "    image_url = jpl_url[:-1] + url_last \n",
    "print('image url --> ' + image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mars_weather = Sol 2026 (April 18, 2018), Sunny, high -6C/21F, low -73C/-99F, pressure at 7.19 hPa, daylight 05:26-17:21\n"
     ]
    }
   ],
   "source": [
    "# Scrape Weather from Twitter Page using Soup\n",
    "twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "response = requests.get(twitter_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "print('mars_weather = ' + mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>description</th>\\n      <th>value</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://space-facts.com/mars/'\n",
    "# Use pandas to read all tables from the web page into an array of dataframes\n",
    "df = pd.read_html(url)\n",
    "df[0].columns = ['description','value']\n",
    "# Assign a dataframe with an html table\n",
    "mars_html_table = df[0].to_html(index=False)\n",
    "mars_html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemisperes\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemipshere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with  Browser('chrome', **executable_path, headless=False) as browser:\n",
    "    astro_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    # open web page\n",
    "    browser.visit(astro_url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all('div', class_='item')\n",
    "    mars_images = []\n",
    "    # Read through items to get images from second page\n",
    "    for first_page in results:\n",
    "        # Get image title from first page\n",
    "        title_text = first_page.h3.text\n",
    "        # Click on title's link on first page and go to second page\n",
    "        browser.click_link_by_partial_text(first_page.h3.text)\n",
    "        # Wait for second page processing\n",
    "        time.sleep(2)\n",
    "        # Get second page's url\n",
    "        page2_url = browser.url\n",
    "        # Visit second page so parsing can begin\n",
    "        browser.visit(page2_url)\n",
    "        # Get second page's html for parsing\n",
    "        html2 = browser.html\n",
    "        # Begin parse of second page using beautifulsoup\n",
    "        soup2 = BeautifulSoup(html2, 'html.parser')\n",
    "        # Get Sample image's url on second page\n",
    "        img_url = soup2.find('a',href=True, text='Sample')['href']\n",
    "        # Save title and image url to list of dicts\n",
    "        mars_images.append({\"title\" : title_text,\"img_url\" : img_url})\n",
    "        # Go back to first page\n",
    "        browser.back()\n",
    "    print(mars_images)                              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
