{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News title --> NASA Engineers Dream Big with Small Spacecraft\n",
      "News paragraph --> \n",
      "The first CubeSat mission to deep space will launch in May.\n",
      "image url --> //www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19964_ip.jpg\n",
      "mars_weather = Sol 2026 (April 18, 2018), Sunny, high -6C/21F, low -73C/-99F, pressure at 7.19 hPa, daylight 05:26-17:21\n",
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th>description</th>\n",
      "      <th>value</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>Equatorial Diameter:</td>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Polar Diameter:</td>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mass:</td>\n",
      "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Moons:</td>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Distance:</td>\n",
      "      <td>227,943,824 km (1.52 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Period:</td>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Surface Temperature:</td>\n",
      "      <td>-153 to 20 Â°C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>First Record:</td>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Recorded By:</td>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "\n",
    "# NASA Mars News\n",
    "# Scrape the NASA Mars News Site and collect the latest \n",
    "# News Title and Paragragh Text. Assign the text to \n",
    "# variables that you can reference later.\n",
    "#\n",
    "# Use a splinter here since the web page has to be fully \n",
    "# rendered (js executed) before we are able to get\n",
    "# the latest title and paragraph \n",
    "with  Browser('chrome', **executable_path, headless=True) as browser:\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    # open web page\n",
    "    browser.visit(url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # find latest title and paragraph\n",
    "    news_title = soup.find('div', class_='content_title').a.text\n",
    "    news_p = soup.find('div', class_='article_teaser_body').text\n",
    "print('News title --> ' + news_title)\n",
    "print('News paragraph --> \\n' + news_p)\n",
    "\n",
    "# JPL Mars Space Images - Featured Image\n",
    "with  Browser('chrome', **executable_path, headless=True) as browser:\n",
    "    jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    # open web page\n",
    "    browser.visit(jpl_url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Get url for image jpg\n",
    "    jpl_url = soup.find('div', class_= 'jpl_logo').a['href']\n",
    "    url_last = soup.find('div', class_='default floating_text_area ms-layer').footer.a['data-fancybox-href']\n",
    "    image_url = jpl_url[:-1] + url_last \n",
    "print('image url --> ' + image_url)\n",
    "\n",
    "# Mars Weather\n",
    "\n",
    "# Scrape Weather from Twitter Page using Soup\n",
    "twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "response = requests.get(twitter_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "print('mars_weather = ' + mars_weather)\n",
    "\n",
    "# Mars Facts\n",
    "\n",
    "url = 'http://space-facts.com/mars/'\n",
    "# Use pandas to read all tables from the web page into an array of dataframes\n",
    "df = pd.read_html(url)\n",
    "df[0].columns = ['description','value']\n",
    "# Assign a dataframe with an html table\n",
    "mars_html_table = df[0].to_html(index=False)\n",
    "print(mars_html_table)\n",
    "\n",
    "# Mars Hemisperes\n",
    "\n",
    "with  Browser('chrome', **executable_path, headless=False) as browser:\n",
    "    astro_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    # open web page\n",
    "    browser.visit(astro_url)\n",
    "    # scrape web page using beautiful soup\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all('div', class_='item')\n",
    "    mars_images = []\n",
    "    # Read through items to get images from second page\n",
    "    for first_page in results:\n",
    "        # Get image title from first page\n",
    "        title_text = first_page.h3.text\n",
    "        # Click on title's link on first page and go to second page\n",
    "        browser.click_link_by_partial_text(first_page.h3.text)\n",
    "        # Wait for second page processing\n",
    "        time.sleep(2)\n",
    "        # Get second page's url\n",
    "        page2_url = browser.url\n",
    "        # Visit second page so parsing can begin\n",
    "        browser.visit(page2_url)\n",
    "        # Get second page's html for parsing\n",
    "        html2 = browser.html\n",
    "        # Begin parse of second page using beautifulsoup\n",
    "        soup2 = BeautifulSoup(html2, 'html.parser')\n",
    "        # Get Sample image's url on second page\n",
    "        img_url = soup2.find('a',href=True, text='Sample')['href']\n",
    "        # Save title and image url to list of dicts\n",
    "        mars_images.append({\"title\" : title_text,\"img_url\" : img_url})\n",
    "        # Go back to first page\n",
    "        browser.back()\n",
    "    print(mars_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
